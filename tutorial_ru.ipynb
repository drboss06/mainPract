{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Mining с sberpm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Библиотека __`sberpm`__ предназначена для анализа и исследования процессов, построения их в виде графов и решения смежных задач классификации и кластеризации с использованием алгоритмов машинного обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Для получения полной версии библиотеки, напишите письмо с запросом на aabugaenko@sberbank.ru__\n",
    "\n",
    "__Страница платформы SberPM:\n",
    "https://developers.sber.ru/portal/products/sber-process-mining__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![title](poster_PM/poster.png)](https://developers.sber.ru/portal/products/sber-process-mining)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оглавление\n",
    "\n",
    "[----------  Предварительная обработка данных  ----------](#------------Предварительная-обработка-данных------------)\n",
    "\n",
    "I. [Мэтчинг таблиц](#I.-Мэтчинг-таблиц)\n",
    "\n",
    "II. [Генератор логов](#II.-Генератор-логов) # в полной версии библиотеки\n",
    "\n",
    "III. [Синтетические ID процесса](#III.-Синтетические-ID-процесса)  # в полной версии библиотеки\n",
    "\n",
    "IV. [DataHolder](#IV.-DataHolder)\n",
    "\n",
    "[----------  Автоматическое исследование с помощью искусственного интеллекта  ----------](#------------Автоматическое-исследование-с-помощью-искусственного-интеллекта------------) # в полной версии библиотеки\n",
    "\n",
    "[----------  Традиционный Process Mining  ----------](#----------Традиционный-Process-Mining----------)\n",
    "\n",
    "I. [Майнеры и визуализация графов](#I.-Майнеры-и-визуализация-графов)\n",
    " 1. [SimpleMiner](#1.-SimpleMiner)\n",
    " 2. [CausalMiner](#2.-CausalMiner)\n",
    " 3. [HeuMiner](#3.-HeuMiner)\n",
    " 4. [AlphaMiner](#4.-AlphaMiner)\n",
    " 5. [AlphaPlusMiner](#5.-AlphaPlusMiner)\n",
    " 6. [InductiveMiner](#6.-InductiveMiner)\n",
    " 7. [ML-miners](#7.-ML-miners)\n",
    " 8. [NLP-Miner](#8.-NLP-miner) # в полной версии библиотеки\n",
    " 9. [Correlation-Miner](#9.-Correlation-miner)\n",
    " 10. [II-miner](#10.-II-miner)\n",
    "\n",
    "II. [Метрики](#II.-Метрики)\n",
    "- [Метрики + графы](#Метрики-+-графы)\n",
    "\n",
    "III. [Conformance Checking](#III.-Conformance-Checking)\n",
    "\n",
    " IV. [BPMN](#IV.-BPMN)\n",
    "\n",
    "V. [Визуализация](#V.-Визуализация)\n",
    "\n",
    "[---------- Машинное-обучение ----------](#----------Машинное-обучение----------)\n",
    "\n",
    "I. [Кластеризация этапов](#I.-Кластеризация-этапов) # в полной версии библиотеки\n",
    "\n",
    "II. [Автоматический поиск неэффективностей](#II.-Автоматический-поиск-неэффективностей) # в полной версии библиотеки\n",
    "\n",
    "III. [Поиск аномалий](#III.-Поиск-аномалий) \n",
    "\n",
    "IV. [Факторный анализ](#IV.-Факторный-анализ) # в полной версии библиотеки\n",
    "\n",
    "V. [Модуль автоматического построения моделей](#V.-Модуль-автоматического-построения-моделей) # в полной версии библиотеки\n",
    "\n",
    "VI. [Рекомендательная система](#VI.-Рекомендательная-система) # в полной версии библиотеки\n",
    "\n",
    "VII. [Анализ текстов](#VII.-Анализ-текстов) # в полной версии библиотеки\n",
    "\n",
    "VIII. [Сентиментный анализ](#VIII.-Сентиментный-анализ) # в полной версии библиотеки\n",
    "\n",
    "IX. [Поиск счастливого пути](#IX.-Поиск-счастливого-пути) # в полной версии библиотеки\n",
    "\n",
    "X. [Предсказание структуры графа](#X.-Предсказание-структуры-графа) # в полной версии библиотеки\n",
    "\n",
    "XI. [Имитационное моделирование и what-if анализ](#XI.-Имитационное-моделирование-и-what-if-анализ)\n",
    "\n",
    "XII. [Decision Mining](#XII.-Decision-Mining)\n",
    "\n",
    "XIII. [Хронометраж](#XII.-Хронометраж)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------  Предварительная обработка данных  ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Мэтчинг таблиц\n",
    "\n",
    "Данный модуль **`sberpm.column_matching`** представляет собой систему для анализа значения столбцов в двух таблицах. Анализ производится по текстовым и численным колонкам. Колонки, у которых будут похожие значения в разных таблицах, будут сопоставляться. \n",
    "\n",
    "Параметры, передаваемые в класс **ColumnMatching**:\n",
    "* **data_left (pandas DataFrame)** - первая таблица для сравнения\n",
    "* **data_right (pandas DataFrame)** - вторая таблица для сравнения\n",
    "* **p_value_threshold (float = default 0.05)** - порог для p-value теста Колмогорова-Смирнова для численных колонок\n",
    "* **iou_threshold (float = default 0.5)** - порог для метрики IOU для текстовых колонок\n",
    "\n",
    "Методы класса **`ColumnMatching`**:\n",
    "- **get_result_pairs** возвращает пары с похожими колонками из левой и правой таблице.\n",
    "- **get_result_table** возвращает сводную таблицу, в которой по осям колонки из левой и правой таблице, а в ячейках меры похожести соответствующих колонок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from sberpm.column_matching import ColumnMatching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тест на тривиальных синтетических данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_left = DataFrame({\n",
    "    \"names left\": [\"Alexander FFFFF\", \"Andrew Alexander\", \"Ilya Emilia\", \"Ilya Alexander\"] * 50,\n",
    "    \"last names left\": [\"Arkhipov\", \"Kuznetsova\", \"Kuznetsova\", \"Bugaenko\"] * 50,\n",
    "})\n",
    "data_right = DataFrame({\n",
    "    \"names right\": [\"Seva Alexander\", \"Alexander Vera\", \"Ilya Andrew\"] * 50,\n",
    "    \"last names right\": [\"Zarubin\", \"Zarubin\", \"Kuznetsova\"] * 50,\n",
    "})\n",
    "\n",
    "column_map = ColumnMatching(\n",
    "    data_left,\n",
    "    data_right,\n",
    "    p_value_threshold=0.05,\n",
    "    iou_threshold=0.25,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_map.map_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_map.get_result_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_map.get_result_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Генератор логов\n",
    "##### <font color='red'>В полной версии библиотеки</font>\n",
    "__LogGenerator__ - позволяет автоматически генерировать логи процессов, так же его возможно настроить под конкретную задачу. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Синтетические ID процесса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color='red'>В полной версии библиотеки</font>\n",
    "\n",
    "__Pro_n_check__ нумерует экземпляры процессов в зависимости от заданных условий. Создает столбец 'pro_n'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. DataHolder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataHolder` – это базовый класс для хранения данных. Практически все алгоритмы библиотеки работают с ним (принимают на вход).\n",
    "\n",
    "Для создания класса `DataHolder` необходимо сперва указать путь к файлу или передать DataFrame конструктору, а затем указать __id_column__ и __activity_column__. Однако, для большинства алгоритмов Process Mining, представленных в библиотеке, этих столбцов недостаточно – необходимы хотя бы одна колонка времени (__start_timestamp_column__ и/или __end_timestamp_column__) и колонка пользователей (__user_column__). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Параметры DataHolder\n",
    "- **data (str or pd.DataFrame)** – путь к файлу данных (.csv, .xls(x), .txt) или pd.DataFrame\n",
    "- **id_column (str)** – столбец id\n",
    "- **activity_column (str)** – столбец активностей\n",
    "- __<font color='red'>*</font>start_timestamp_column (str)__ – время начала активностей\n",
    "- __<font color='red'>*</font>end_timestamp_column (str)__ – время окончания активностей\n",
    "- __user_column (str)__ – столбец с именами/id пользователей\n",
    "- __text_column (str)__ – столбец с текстовыми данными\n",
    "- __duration_column (str)__ – столбец с длительностями активностей (если не задается, то расчитывается как время_активности_2 - время_активности_1, причем если есть только один столбец со временем, то для последней активности в цепочке ставится NaN)\n",
    "- __duration_unit (str)__ – размерность (единица измерения) значений в столбце duration_column, если он задан\n",
    "\n",
    "- __sep (str, default=',')__ – разделительный знак (используется только при чтении данных из файла)\n",
    "- __encoding (str)__ – кодировка (используется только при чтении данных из файла)\n",
    "- __nrows (int)__ – количество строк для чтения (используется только при чтении данных из файла)\n",
    "\n",
    "- __preprocess (bool, default=True)__ – предобработка данных (сортировка, удаление None-значений, преобразование типов)\n",
    "- __time_format (str)__ – формат временных колонок (обязательно задавать для правильного распознавания даты и ускорения работы). Правила написания: https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes\n",
    "- __time_errors: (str, default='raise')__ – действие при ошибке конвертации\n",
    "- __dayfirst: (bool, default=None)__ – True, если день стоит в начале строки\n",
    "- __yearfirst: (bool, default=None)__ – True, если год стоит в начале строки\n",
    "- __n_jobs (int, default=1)__ – максимальное количество потоков, доступное для некоторых вычислений\n",
    "\n",
    "\n",
    "__<font color='red'>*</font>__ Для большинства алгоритмов нужно задать хотя бы один из временных столбцов. Если нет информации о типе столбца (время начала или конца), следует задать его как __start_timestamp_column__. Для верного распознавания формата также необходимо указать __time_format__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исследуемые данные должны представлять собой журнал событий (лог-файл), в котором хранится информация о последовательности (цепочке) событий (активностей) в бизнес-процессах. Пример журнала событий: $W = \\{(a,b,c,d), (a,c,b,d), (a,e,d)\\}$, где события $a$, $b$, $c$, $d$ и $e$ сортируются по времени."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание DataHolder \n",
    "### – с помощью DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sberpm import DataHolder\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'id_column': [1, 1, 2, 2, 3, 3],\n",
    "                   'activity_column': ['st1', 'st2', 'st1', 'st3', 'st1','st2'],\n",
    "                   'start_timestamp_column': ['10.05.2020', '10.09.2020', '10.03.2020', '10.04.2020', '10.05.2020', '10.05.2020']})\n",
    "\n",
    "data_holder = DataHolder(data=df, \n",
    "                         id_column='id_column', \n",
    "                         activity_column='activity_column', \n",
    "                         start_timestamp_column='start_timestamp_column', \n",
    "                         time_format='%d.%m.%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### – с помощью указания пути файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path = 'example.xlsx'\n",
    "data_holder = DataHolder(data=path, \n",
    "                         id_column='id', \n",
    "                         activity_column='stages', \n",
    "                         start_timestamp_column='dt', \n",
    "                         user_column='users', \n",
    "                         text_column=\"some_text\",\n",
    "                         time_format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если данные имеют какой-нибудь разделитель, например '|' как в csv, то после задания колонок, нужно задать параметр __sep='|'__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Атрибуты DataHolder\n",
    "В `DataHolder` названия столбцов хранятся в соответствующих переменных (т.е. нет необходимости запоминать названия колонок):\n",
    "- id_column\n",
    "- activity_column\n",
    "- start_timestamp_column\n",
    "- end_timestamp_column\n",
    "- user_column\n",
    "- text_column\n",
    "- duration_column\n",
    "\n",
    "Кроме того, в `DataHolder` хранятся исходные и сгруппированные данные в виде DataFrame, к которым можно обратиться следующим образом:\n",
    "- data\n",
    "- grouped_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Методы DataHolder\n",
    "- __check_or_calc_duration__ – рассчитывает длительность каждой активности (в секундах), если это необходимо \n",
    "- __get_grouped_data__ – выводит сгруппированные данные по id и указанным колонкам (например, по activity_column и start_timestamp_column)\n",
    "- __get_unique_activities__ – выводит список уникальных активностей\n",
    "- __get_columns__ – выводит список с названиями колонок \n",
    "- __get_text__ – выводит колонку с текстом, если такая есть\n",
    "- __get_timestamp_col__ – выводит временную колонку; если их имеется 2, то выводит start_time_column\n",
    "- __is_interval__ – возвращает True, если это \"интервальный лог\" (у которого имеются обе временные колонки: начала и конца активности)\n",
    "- __top_traces_dh__ – возвращает data_holder с данными для n самых частых цепочек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_holder.check_or_calc_duration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_holder.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_holder.get_grouped_data(data_holder.activity_column, data_holder.start_timestamp_column).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh_3 = data_holder.top_traces_dh(3)  # данные только для топ 3 цепочек\n",
    "dfg = dh_3.get_grouped_data(dh_3.activity_column)\n",
    "dfg.value_counts(dh_3.activity_column)  # проверка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Имея данные о бизнес-процессе с цепочками статусов и временем начала каждого из них, можно загрузить их в `DataHolder` и построить граф, максимально описывающий этот бизнес-процесс."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------  Автоматическое исследование с помощью искусственного интеллекта  ----------\n",
    "\n",
    "##### <font color='red'>В полной версии библиотеки</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Данный модуль в автоматическом режиме создаёт исследование в виде презентации с отображением диаграмм и графиков, а так же делает выводы на основе полученных результатов. \n",
    "\n",
    "[Автоматическое исследование с помощью искусственного интеллекта (beta версия)](#Автоматическое-исследование-с-помощью-искусственного-интеллекта-(beta-версия))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------Традиционный Process Mining----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Майнеры и визуализация графов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для построения и отрисовки графа процесса в библиотеке реализовано несколько алгоритмов. Все они хранятся в модуле __`sberpm.miners`__ и имеют один метод:\n",
    "- __apply__ – строит граф, который сохраняется в поле graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. SimpleMiner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SimpleMiner` отрисовывает все ребра, найденные в логе (без какой-либо фильтрации).\n",
    "\n",
    "В терминах Process Mining:\n",
    "> Если хотя бы в одной цепочке активностей из лога за некоторой активностью $X$ непосредственно следует активность $Y$ (цепочка вида $...XY...$), то пишут $X>Y$ ($Y$ follows $X$, _follows_ relation).\n",
    "\n",
    "SimpleMiner рисует ребра между такими парами активностей $X$ и $Y$, если выполняется $X>Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sberpm.miners import SimpleMiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание объекта SimpleMiner. В конструктор подается DataHolder и параметры алгоритма \n",
    "# (у данного майнера параметров нет)\n",
    "simple_miner = SimpleMiner(data_holder)\n",
    "\n",
    "# Запуск алгоритма построения графа\n",
    "simple_miner.apply()\n",
    "\n",
    "# Сохранение графа\n",
    "graph = simple_miner.graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Визуализация графа\n",
    "Для визуализации графа следует использовать `GraphvizPainter` из модуля __`sberpm.visual`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sberpm.visual import GraphvizPainter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Класс `GraphvizPainter` имеет методы:\n",
    "- __apply__ – принимает на вход граф, полученный с помощью майнера, и производит расчет для его отрисовки \n",
    "- __write_graph__ – сохраняет граф в требуемом формате (pdf, svg, gv, png)\n",
    "- __show__ – выводит граф в notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Создание объекта GraphvizPainter\n",
    "painter = GraphvizPainter()\n",
    "\n",
    "# Расчет графа по результатам работы SimpleMiner\n",
    "painter.apply(graph)\n",
    "\n",
    "# Можно сохранить граф на жесткий диск в формате png, svg, pdf или gv\n",
    "painter.write_graph('SimpleMiner.png', format='png')\n",
    "\n",
    "# Можно вывыести граф в notebook\n",
    "painter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс `Graph` из модуля __`sberpm.visual`__ имеет методы:\n",
    "- __get_nodes__ – получить все узлы\n",
    "- __get_edges__ – получить все ребра\n",
    "- __add_node_metric__ – добавить метрику, связанную с узлами графа\n",
    "- __add_edge_metric__ – добавить метрику, связанную с ребрами графа\n",
    "- __clear_node_metrics__ – удалить все метрики с нод (узлов)\n",
    "- __clear_edge_metrics__ – удалить все метрики с ребер"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. CausalMiner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CausalMiner` основан на фильтрации ребер.\n",
    "> Производные типы связей от $X>Y$:\n",
    "- прямые связи ($X \\to Y$, _causal_ relation) – это связи, где $Х>Y$ и не $Y>X$\n",
    "- параллельные связи($X\\parallel Y $, _parallel_ relation) – это связи, где $Х>Y$ и $Y>X$\n",
    "- независимые связи ($X\\#Y$, independent) – это связи, где не $X>Y$ и не $Y>X$\n",
    "\n",
    "CausalMiner рисует ребра между такими парами активностей $X$ и $Y$, если выполняется $X\\to Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "from sberpm.miners import CausalMiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Майнер\n",
    "causal_miner = CausalMiner(data_holder)\n",
    "causal_miner.apply()\n",
    "graph = causal_miner.graph\n",
    "\n",
    "# Отрисовка\n",
    "painter = GraphvizPainter()\n",
    "painter.apply(graph)\n",
    "painter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. HeuMiner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`HeuMiner` – это эвристический майнер, который удаляет наиболее редкие связи в зависимости от задаваемого порога (threshold). \n",
    "\n",
    "Параметр **threshold** принимает значения **от 0 до 1**. Чем он больше, тем меньше ребер на графе (оставшиеся ребра считаются более важными).\n",
    "\n",
    "Источник: https://www.researchgate.net/publication/229124308_Process_Mining_with_the_Heuristics_Miner-algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sberpm.miners import HeuMiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Майнер\n",
    "heu_miner = HeuMiner(data_holder, threshold=0.8)\n",
    "heu_miner.apply()\n",
    "graph = heu_miner.graph\n",
    "\n",
    "# Отрисовка\n",
    "painter = GraphvizPainter()\n",
    "painter.apply(graph)\n",
    "painter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4. AlphaMiner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`AlphaMiner` рисует граф в виде сетей Петри с учетом прямых, параллельных и независимых связей между активностями. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sberpm.miners import AlphaMiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Майнер\n",
    "alpha_miner = AlphaMiner(data_holder)\n",
    "alpha_miner.apply()\n",
    "graph = alpha_miner.graph\n",
    "\n",
    "# Отрисовка\n",
    "painter = GraphvizPainter()\n",
    "painter.apply(graph)\n",
    "painter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 5. AlphaPlusMiner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`AlphaPlusMiner` – имплементация Alpha+ майнера, который также рисует граф в виде сетей Петри с учетом связей, но в отличие от AlphaMiner может работать с одноцикловыми (one-loop) цепочками вида activity_1$\\to$activity_1 (самоцикл)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sberpm.miners import AlphaPlusMiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Майнер\n",
    "alpha_miner_plus = AlphaPlusMiner(data_holder)\n",
    "alpha_miner_plus.apply()\n",
    "graph = alpha_miner_plus.graph\n",
    "\n",
    "# Отрисовка\n",
    "painter = GraphvizPainter()\n",
    "painter.apply(graph)\n",
    "painter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. InductiveMiner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`InductiveMiner` создаёт дерево процесса. Лисья дерева - реальные активности процесса, остальные вершины - операторы. Есть 4 типа операторов: \n",
    "- ПОСЛЕДОВАТЕЛЬНЫЙ (`->`), \n",
    "- ИСКЛЮЧАЮЩЕЕ ИЛИ (`X`), \n",
    "- ПАРАЛЛЕЛЬНЫЙ (`||`), \n",
    "- ЦИКЛ (`*`).\n",
    "\n",
    "Есть дополнительный 'оператор', который говорит о том, что было невозможно найти ни один из 4 операторов, представленных выше:\n",
    "- СМЕШЕННАЯ  МОДЕЛЬ ('`?`')\n",
    "\n",
    "*Замечание*: некоторые из листьев дерева могут быть *скрытыми активностями*, отображаемыми чёрными прямоугольниками. Они не являются реальными активностями и используются только для сохранения правильной структуры дерева. \n",
    "\n",
    "Например, из лога, состоящего из двух цепочек процесса $W = \\{(a, b, c), (a, c)\\}$, можно получить следующее дерево процеса:        \n",
    "`->(a, X(b, скрытая_активность), c)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если во время очередной итерации алгоритм не может найти разрез графа (=подобрать один из 4 операторов), возможно добавить следующее поведение: если существует активность А, при удалении которой удаётся подобрать оператор, алгоритм возвращает следующее дерево:            \n",
    "`||(X(активность_А, скрытая_активность), граф_без_активности_А)` - то есть активность А считается параллельной остальному графу.\n",
    "\n",
    "\n",
    "Это поведение может быть включено или выключено параметром **parallel_activity** в классе `InductiveMiner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sberpm.miners import InductiveMiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miner\n",
    "inductive_miner = InductiveMiner(data_holder)\n",
    "inductive_miner.apply()\n",
    "graph = inductive_miner.graph\n",
    "\n",
    "# Visualization\n",
    "painter = GraphvizPainter()\n",
    "painter.apply(graph)\n",
    "painter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. __ML-miners__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sberpm.miners import MLMiner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ML-miner__ - майнер основанный на lasso-регрессии. \n",
    "\n",
    "В данном майнере подсчитываются количество повторений каждого этапа в каждом процессе. Рассчитывается лассо-регрессия, в которой столбец одного вида деятельности рассматривается как цель, а остальные столбцы других видов деятельности - как признаки. На ребрах графа отображаются только те отношения, которые имеют абсолютное значение коэффициента лассо-регрессии больше, чем значение порогового значения.\n",
    "\n",
    "``ML-miner`` рисует ребра между такими парами активностей $X$ и $Y$, если $X$ влияет на $Y$.\n",
    "\n",
    "* data_holder : DataHolder\n",
    "    Объект, содержащий журнал событий и имена его необходимых колонок.\n",
    "\n",
    "* threshold: float (По умолчанию 0.05)\n",
    "    Порог абсолютного значения коэффициента регрессии. Значения превышающие пороговое значение, считаются значимыми связями между деятельностью.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miner\n",
    "ml_miner = MLMiner(data_holder, threshold=0.1)\n",
    "ml_miner.apply()\n",
    "graph = ml_miner.graph\n",
    "\n",
    "# Visualization\n",
    "painter = GraphvizPainter()\n",
    "painter.apply(graph)\n",
    "painter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Auto-miner__\n",
    "\n",
    "``Auto-miner`` основан на Sequence Feature Selector.\n",
    "\n",
    "``Auto-miner`` рисует ребра между такими парами активностей $X$ и $Y$, если $X$ влияет на $Y$.\n",
    "\n",
    "* data_holder : DataHolder\n",
    "    Объект, содержащий журнал событий и имена его необходимых столбцов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sberpm.miners import AutoMiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miner\n",
    "autominer = AutoMiner(data_holder)\n",
    "autominer.apply()\n",
    "graph = autominer.graph\n",
    "\n",
    "# Visualization\n",
    "painter = GraphvizPainter()\n",
    "painter.apply(graph)\n",
    "painter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. __NLP-miner__\n",
    "\n",
    "##### <font color='red'>В полной версии библиотеки</font>\n",
    "\n",
    "``NLP-miner`` использует для анализа этапов процесса библиотеку ``navec``.\n",
    "\n",
    "``NLP-miner`` объединяет активности $X$ и $Y$ и удаляет ребра между $X$ и $Y$, если название $X$ похоже на $Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. __Correlation-miner__\n",
    "\n",
    "``Correlation-miner`` может создать граф журнала событий, в котором нет графы ID экземпляра процесса.\n",
    "\n",
    "Граф будет иметь метрику 'count' для узлов и ребер.\n",
    "\n",
    "``Correlation-miner`` использует линейное программирование, чтобы восстановить утраченные экземпляры процесса на основе времени каждого этапа.\n",
    "\n",
    "* data_holder: DataHolder\n",
    "    Объект, содержащий журнал событий и имена его необходимых колонки.\n",
    "\n",
    "* greedy: bool, default=True\n",
    "    Если True, матрица длительности времени вычисляется жадным способом. Существует вероятность, что решение не будет оптимальным, но это значительно сокращает время и память для больших журналов.\n",
    "\n",
    "* sparse: bool, default=False\n",
    "    Используется только когда greedy=False. Если значение True, вычисление матрицы длительности будет производиться с использованием разреженной матрицы. Это может немного увеличить время вычислений, но немного уменьшить память.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sberpm.miners import CorrelationMiner\n",
    "\n",
    "# Miner\n",
    "corr_miner = CorrelationMiner(data_holder)\n",
    "corr_miner.apply()\n",
    "graph = corr_miner.graph\n",
    "\n",
    "# Visualization\n",
    "painter = GraphvizPainter()\n",
    "painter.apply(graph)\n",
    "painter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. __II-miner__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Майнер для анализа параллельных действий.\n",
    " Подсчитывает пересечения по временным меткам действий.\n",
    " Параллельные этапы - это этапы с такими экземплярами процессов, что время их начала и\n",
    "окончания перекрывается.\n",
    " Добавлен узел `parallel_metric`, который показывает количество пересечений времени на\n",
    "этом этапе и других этапах. От синих узлов стрелки указывают на параллельные этапы.\n",
    "\n",
    "Параметры:\n",
    " data_holder: DataHolder\n",
    " Объект, содержащий журнал событий и имена его необходимых столбцов.\n",
    "\n",
    " Аргументы:\n",
    " graph: добытый график процесса для рисования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sberpm.miners import ParallelMiner\n",
    "\n",
    "# Miner\n",
    "parallel_miner = ParallelMiner(data_holder)\n",
    "parallel_miner.apply()\n",
    "graph = parallel_miner.graph\n",
    "\n",
    "# Visualization\n",
    "painter = GraphvizPainter()\n",
    "painter.apply(graph)\n",
    "painter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## II. Метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данный момент в модуле __`sberpm.metrics`__ есть 5 основных типов метрик:\n",
    "1. `ActivityMetric` – метрики по активностям (группировка по activity_column)\n",
    "2. `TransitionMetric` – метрики по переходам (группировка по уникальным переходам)\n",
    "3. `IdMetric`– метрики по id (группировка по id_column)\n",
    "4. `TraceMetric` – метрики по цепочкам активностей (группировка по уникальным цепочкам)\n",
    "5. `UserMetric` – метрики по пользователям (группировка по user_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sberpm.metrics import ActivityMetric, TransitionMetric, IdMetric, TraceMetric, UserMetric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры:\n",
    "- __data_holder__ – объект типа DataHolder, для которого надо рассчитать метрики\n",
    "- __time_unit__ – единица времени, по умолчанию расчет временных метрик происходит в часах\n",
    "- __round__ – количество цифр после запятой (только для метрик, значения которых могут быть с плавающей точкой)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общие методы для всех классов:\n",
    "- __apply__ – расчет всех характеристик\n",
    "- __calc_metrics(...)__ – расчет указанных метрик (соответствуют методам/названиям колонок в DataFrame из apply)\n",
    "- __calculate_time_metrics__ – расчет временных характеристик\n",
    "\n",
    "- __total_duration__ – расчет суммарного времени работы\n",
    "- __min_duration__ – расчет минимального времени работы\n",
    "- __max_duration__ – расчет максимального времени работы\n",
    "- __mean_duration__ – расчет среднего времени работы\n",
    "- __median_duration__ – расчет медианного времени работы\n",
    "- __std_duration__ – расчет стандартного отклонения времени работы\n",
    "- __var_duration__ – расчет дисперсии времени работы\n",
    "\n",
    "Дополнительные методы:\n",
    "- ActivityMetric\n",
    "    - __count__ - сколько раз активность встречается в логе\n",
    "    - __unique_ids__ - уникальные id для каждой активности\n",
    "    - __unique_ids_num__ - количество уникальных id для каждой активности\n",
    "    - __aver_count_in_trace__ - среднее количество раз встречаемости активности в цепочке\n",
    "    - __loop_percent__ - процент зацикленности\n",
    "    - __throughput__ - частота - количество выполненных активностей за единицу времени\n",
    "    - __unique_users__ - уникальные пользователи, работавшие с данной активностью\n",
    "    - __unique_users_num__ - количество уникальных пользователей, работающих над данной активностью\n",
    "    - __success_rate(...)__ - доля id, имеющих данную активность, которая выполнилась успешно (закончились успешными активностями)\n",
    "    - __failure_rate(...)__ - доля id, имеющих данную активность, которая выполнилась неуспешно (закончились неуспешными активностями)\n",
    "    \n",
    "    \n",
    "- IdMetric\n",
    "    - __trace__ - цепочка (список активностей)\n",
    "    - __trace_length__ - длина цепочки (кол-во активностей в цепочке)\n",
    "    - __unique_activities__ - уникальные активности в цепочке\n",
    "    - __unique_activities_num__ - количество уникальных активностей в цепочке\n",
    "    - __loop_percent__ - процент зацикленности\n",
    "    - __unique_users__ - уникальные пользователи, работающие с этим ID\n",
    "    - __unique_users_num__ - кол-во уникальных пользователей, работавших с данным ID\n",
    "\n",
    "- TraceMetric\n",
    "    - __count__ - сколько раз данная цепочка встречается в логе\n",
    "    - __ids__ - уникальные id с данной цепочкой\n",
    "    - __trace_length__ - длина цепочки (кол-во активностей в цепочке)\n",
    "    - __unique_activities__ - уникальные активности в цепочке\n",
    "    - __unique_activities_num__ - количество уникальных активностей в цепочке активностей\n",
    "    - __unique_users__ - уникальные пользователи, работающие над цепочкой активностей\n",
    "    - __unique_users_num__ - количество уникальных пользователей, работающих над цепочкой активностей\n",
    "\n",
    " \n",
    "- TransitionMetric\n",
    "    - __count__ - сколько раз данный переход встречается в логе\n",
    "    - __unique_ids__ - уникальные id  для каждого перехода\n",
    "    - __unique_ids_num__ - количество уникальных id для каждого перехода\n",
    "    - __aver_count_in_trace__ - среднее количество раз встречаемости объекта в цепочке\n",
    "    - __loop_percent__ - процент зацикленности\n",
    "    - __throughput__ - частота - количество выполненных переходов за единицу времени\n",
    "    - __unique_users__ - уникальные пользователи, работающие над объектом\n",
    "    - __unique_users_num__ - кол-во уникальных пользователей, работающих над объектом\n",
    "    - __success_rate(...)__ - доля id, имеющих текущий переход, которые выполнились успешно (закончились успешными активностями)\n",
    "    - __failure_rate(...)__ - доля id, имеющих текущий переход, которые выполнились неуспешно (закончились неуспешными активностями)\n",
    "    \n",
    "    \n",
    "- UserMetric\n",
    "    - __count__ - сколько раз данный пользователь встречается в логе\n",
    "    - __unique_activities__ - уникальные активности, с которыми работал пользователь\n",
    "    - __unique_activities_num__ - количество уникальных активностей, с которыми работал пользователь\n",
    "    - __unique_ids__ - уникальные id с данным пользователем\n",
    "    - __unique_ids_num__ - количество уникальных id с данным пользователем\n",
    "    - __throughput__ - число раз выполнения объекта за единицу времени\n",
    "    - __workload__ - доля активности лога, выполненных данным пользователем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ActivityMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Создание объекта ActivityMetric\n",
    "activity_metric = ActivityMetric(data_holder, time_unit='d')\n",
    "\n",
    "# Расчет всех метрик\n",
    "activity_metric.apply().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2. TransitionMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Создание объекта TransitionMetric\n",
    "transition_metric = TransitionMetric(data_holder, time_unit='d')\n",
    "\n",
    "# Расчет всех метрик\n",
    "transition_metric.apply().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3. IdMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Создание объекта IdMetric\n",
    "id_metric = IdMetric(data_holder, time_unit='d')\n",
    "\n",
    "# Расчет всех метрик\n",
    "id_metric.apply().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4. TraceMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Создание объекта TraceMetric\n",
    "trace_metric = TraceMetric(data_holder, time_unit='d')\n",
    "\n",
    "# Расчет всех метрик\n",
    "trace_metric.apply().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 5. UserMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Создание объекта UserMetric\n",
    "user_metric = UserMetric(data_holder, time_unit='d')\n",
    "\n",
    "# Расчет всех метрик\n",
    "user_metric.apply().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Метрики + графы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В библиотеке реализована возможность представить ряд метрик на графе. Сделать это можно в классе `Graph` с помощью методов:\n",
    "- __add_node_metric__ – добавить метрику, связанную с узлами графа\n",
    "- __add_edge_metric__ – добавить метрику, связанную с ребрами графа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Расчет метрик\n",
    "nodes_count_metric = activity_metric.count().to_dict()\n",
    "edges_count_metric = transition_metric.count().to_dict()\n",
    "mean_time_node_metric = activity_metric.mean_duration().fillna(0).to_dict()\n",
    "\n",
    "# Получение графа из майнера\n",
    "graph = causal_miner.graph\n",
    "\n",
    "# Добавление метрик на граф\n",
    "graph.add_node_metric('count', nodes_count_metric)\n",
    "graph.add_edge_metric('count', edges_count_metric)\n",
    "graph.add_node_metric('mean_time', mean_time_node_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание объекта GraphvizPainter\n",
    "painter = GraphvizPainter()\n",
    "\n",
    "# Отрисовать граф и связать цвет узлов и ребер с нужными метриками\n",
    "painter.apply(graph, node_style_metric='count', edge_style_metric='count')\n",
    "# или painter.apply(graph, node_style_metric='mean_time', edge_style_metric='count')\n",
    "\n",
    "# Сохранение графа\n",
    "painter.write_graph(\"metric_graph.png\", format = 'png')\n",
    "\n",
    "# Отображение в jupyter-notebook\n",
    "painter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы удалить метрики с графа, следует воспользоваться следующими методами:\n",
    "- __clear_node_metrics__ – удалить все метрики с нод (узлов)\n",
    "- __clear_edge_metrics__ – удалить все метрики с ребер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.clear_node_metrics()\n",
    "graph.clear_edge_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Conformance Checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### TokenReplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TokenReplay` позволяет рассчитать *fitness*, который показывает, насколько хорошо граф описывает бизнесс-процесс (1 – хорошо, 0 – плохо). Fitness вычисляется отдельно для каждой цепочки (id) при ее проигрывании по сети Петри по следующей формуле:\n",
    "$$ Fitness = \\frac{1}{2}\\Big(1-\\frac{missed}{consumed}\\Big) + \\frac{1}{2}\\Big(1-\\frac{remaining}{produced}\\Big) $$\n",
    "- produced tokens – появились в результате перехода\n",
    "- consumed tokens – удалились в результате перехода\n",
    "- remaining tokens – остались в конце проигрывания\n",
    "- missing tokens – не было, но они необходимы для проигрывания, поэтому их вставляют\n",
    "\n",
    "Библиотека выдает следующие метрики:\n",
    "- значения 4 величин и fitness каждой цепочки\n",
    "- усредненный fitness по всем цепочкам (__mean_fitness__)\n",
    "- fitness по всему логу – в формулу подставляются суммарные значения 4 величин по всем цепочкам в логе (__average_fitness__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sberpm.conformance_checking import TokenReplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_replay = TokenReplay(data_holder, alpha_miner.graph)\n",
    "token_replay.apply()\n",
    "token_replay.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mean:', token_replay.mean_fitness)\n",
    "print('average:', token_replay.average_fitness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также в библиотеке доступен более общий класс ConformanceChecking, сдержащий TokenReplay и рад других метрик:\n",
    "- precision\n",
    "- generalization\n",
    "- simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sberpm.conformance_checking import ConformanceChecking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = ConformanceChecking(data_holder, alpha_miner.graph)\n",
    "cc.get_conformance_checking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.get_fitness_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## IV. BPMN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сохранения графа в формате BPMN (Business Process Model and Notation) можно воспользоваться `BpmnExporter` из модуля __`sberpm.bpmn`__. Он имеет следующие методы:\n",
    "- __apply_petri__ – построить BPMN для сети Петри\n",
    "- __get_string_representation__ – получить BPMN-нотацию графа\n",
    "- __write__ – записать граф в BPMN формате\n",
    "\n",
    "На данный момент сохранять можно только графы, полученные из Alpha Miner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sberpm.bpmn import BpmnExporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bpmn_exporter = BpmnExporter()\n",
    "bpmn_exporter.apply(alpha_miner.graph)\n",
    "bpmn_exporter.get_string_representation()[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpmn_exporter.write('exported.bpmn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Для загрузки BPMN-файла есть класс `BpmnImporter` со следующими методами:\n",
    "- __load_bpmn_from_xml__ – загрузить граф, представленный в виде BPMN\n",
    "- __get_pydotplus_graph__ – получить граф в формате pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sberpm.bpmn import BpmnImporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bpmn_importer = BpmnImporter()\n",
    "bpmn_importer.load_bpmn_from_xml('exported.bpmn')\n",
    "pydot_graph = bpmn_importer.get_pydotplus_graph()\n",
    "pydot_graph.write('imported_bpmn.svg', prog='dot', format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Визуализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс `ChartPainter` из модуля __`sberpm.visual`__ предназначен для создания основных типов графиков. В основе визуализации лежит библиотека __`plotly`__, благодаря чему все диаграммы являются интерактивными. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sberpm.visual import ChartPainter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры:\n",
    "- __data__ – данные, которые необходимо визуализировать (DataFrame, DataHolder или объекта класса метрик)\n",
    "- __template__ – стиль графиков, по умолчанию _plotly_\n",
    "- __palette__ – цветовая палитра графиков, по умолчанию _sequential.Sunset_r_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый метод `ChartPainter` позволяет отрисовать график определенного типа:\n",
    "- __hist__ – гистограмма\n",
    "- __bar__ – столбчатая диаграмма\n",
    "- __box__ – ящичковая диаграмма\n",
    "- __scatter__ – диаграмма рассеяния\n",
    "- __line__ – линейный график\n",
    "- __pie__ – круговая диаграмма\n",
    "- __sunburst__ – диаграмма солнечные лучи\n",
    "- __heatmap__ – 2D гистограмма\n",
    "- __timeline__ – диаграмма Ганта\n",
    "- __pareto__ – диаграмма Парето\n",
    "\n",
    "Основные параметры методов (для более подробной информации см. документацию):\n",
    "- __x__, __y__ – названия столбцов для отрисовки по осям X и Y соответственно\n",
    "- __sort__ – название столбца для сортировки значений\n",
    "- __n__ – количество строк для визуализации\n",
    "- __color__ – название столбца для задания цвета элементам графика\n",
    "- __subplots__ – кортеж вида (rows, cols, ncols), где rows и cols – это названия столбцов для отрисовки нескольких графиков по рядам и столбцам соответственно, а ncols – это количество столбцов\n",
    "- __text__ – название столбца с текстовой информацией (или ее вид) для отображения на графике\n",
    "- __orientation__ – ориентация графика\n",
    "- __opacity__ – прозрачность элементов графика\n",
    "- __edge__ – границы элементов графика\n",
    "- __title__ – название графика\n",
    "\n",
    "Каждый метод прост в использовании, но при этом обладает достаточно широким функционалом, который позволяет построить графики для любых задач."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гистограмма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "painter = ChartPainter(id_metric)\n",
    "painter.hist(x='total_duration', edge=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Столбчатая диаграмма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "painter = ChartPainter(user_metric)\n",
    "painter.bar(x=data_holder.user_column, y='total_duration', text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Диаграмма рассеяния"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "painter = ChartPainter(id_metric)\n",
    "painter.scatter(x='mean_duration', y='median_duration', color='unique_users_num', size='trace_length', \n",
    "                edge=True, opacity=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Круговая диаграмма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "painter = ChartPainter(user_metric)\n",
    "painter.pie(labels='count', n=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гистограмма распределения активностей по диапазонам времени"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### По всем активностям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "painter = ChartPainter(data_holder)\n",
    "painter.hist_activity_of_dur(top= False, use_median=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### По топ активностям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "painter.hist_activity_of_dur(top= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### По одной активности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "painter.hist_activity_of_dur(by_activity='Stage_6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ----------Машинное обучение----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Кластеризация этапов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color='red'>В полной версии библиотеки</font>\n",
    "\n",
    "Данный модуль служит для кластеризации этапов процесса, для нахождения близких или идентичных этапов процессов. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##  II. Автоматический поиск неэффективностей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color='red'>В полной версии библиотеки</font>\n",
    "\n",
    "Модуль автоматического поиска неэффективностей __`sberpm.autoinsights`__ позволяет в автоматическом режиме выявить __слабые места и уязвимости процесса__ и наглядно продемонстрировать их на графе процесса. При анализе классом `AutoInsights` учитываются такие факторы, как:\n",
    "1. Длительность этапа\n",
    "2. Рост длительности этапа\n",
    "3. Нерегулярность (редкость) этапа\n",
    "4. Этап имеет bottleneck c низкой вариативностью\n",
    "5. Этап имеет bottleneck c высокой вариативностью\n",
    "6. Этап имеет большую длительность из-за частых повторений инцидентов\n",
    "7. Этап имеет большую длительность из-за разовых инцидентов\n",
    "8. Этап приводит к росту времени процесса и/или прочих этапов\n",
    "9. Этап проходит с ошибками, что приводит к замедлению процесса\n",
    "10. Этап проходит с критическими ошибками системы, что приводит к неуспеху процесса\n",
    "11. Этап проходит со структурными ошибками, что приводят к неуспеху процесса\n",
    "12. Сторнирование на данном этапе приводит к неуспеху замедлению процесса\n",
    "13. Сторнирование на данном этапе приводит к неуспеху процесса\n",
    "14. Уровень аномальности\n",
    "15. Сумма финансовых эффектов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## III. Поиск аномалий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Выявление аномалий__ (также __обнаружение выбросов__) — это распознавание во время интеллектуального анализа данных редких данных, событий или наблюдений, которые вызывают подозрения ввиду существенного отличия от большей части данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для поиска аномалий (выбросов) в данных в библиотеке есть модуль __`sberpm.ml.anomaly_detection`__, в котором есть классы `OutlierCBLOF`, `OutlierForest`, `OutlierLOF`, `OutlierOCSVM`, `OutlierCustom`, `OutlierEnsemble`. В каждом классе реализован свой алгоритм __выявления аномалий без учителя__, который обнаруживает аномалии в непомеченных наборах данных при предположении, что большая часть набора данных нормальна, путем поиска представителей, которые меньше подходят к остальному набору данных. \n",
    "\n",
    "`OutlierEnsemble` это композиция алгоритмов обнаружения аномалий, итоговой ответ которой представляет собой голосование (объект считается выбросом, если большинство алгоритмов определило его как выброс) следующих алгоритмов: [KNN](https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.knn), [ABOD](https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.abod), [HBOS](https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.hbos), [Isolation Forest](https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.iforest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sberpm.ml.anomaly_detection import OutlierCBLOF, OutlierForest, OutlierLOF, \\\n",
    "                                        OutlierOCSVM, OutlierCustom, OutlierEnsemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве параметра объект принимает на вход DataHolder, по которому рассчитывает базовые статистики, такие как среднее время, длина цепочки активностей, число уникальных пользователей (если они есть) и т. д. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "outlier_detector = OutlierForest(data_holder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Каждый класс имеет следующие методы:\n",
    "- __add_feature__ – добавление признака, по которому требуется найти аномалии \n",
    "- __add_groupby_feature__ – добавление признака для поиска аномалий, рассчитанного по сгруппированным данным \n",
    "- __apply__ – запуск алгоритма\n",
    "- __get_outlier_ids__ – вывод id аномальных процессов\n",
    "- __print_result__ – вывод статистики по аномалиям\n",
    "- __show_permutation_importance__ – иллюстрация permutation importance признаков, по которым отличаются выбросы (работает везде кроме `OutlierEnsemble`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Добавление признака с именем max_time, вычисляемого путем применения функции max к колонке \n",
    "# data_holder.duration_column в сгруппированных по id данных (масимальное время активности в процессе)\n",
    "outlier_detector.add_groupby_feature('max_time', data_holder.duration_column, max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В модуле реализовано 5 техник выявления аномалий:\n",
    "1. __Isolation Forest (IF)__\n",
    "2. __One-Class Support Vector Machines (OCSVM)__\n",
    "3. __Local Outlier Factor (LOF)__\n",
    "4. __Cluster-Based Local Outlier Factor (CBLOF)__\n",
    "5. `OutlierEnsemble` в котором есть __KNN__, __HBOS__, __ABOD__, __Isolation Forest__\n",
    "\n",
    "Также можно использовать любой другой алгоритм поиска аномалий (например, из библиотеки __pyod__)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolation Forest\n",
    "\n",
    "> В основе техники __изолирующего леса__ лежит идея о том, что аномальные наблюдения легче отделить от остальных (нормальных) объектов датасета. Алгоритм строит ансамбль изолирующих бинарных деревьев решений, в каждом узле которого выбор признака и порога разбиения производится случайным образом. Дерево строится до тех пор, пока в листе не останется только один объект или объекты с одинаковыми значениями. Интуитивно понятно, что __аномальные__ точки – это те, что имеют меньшую длину пути в дереве, которая определяется как число ребер, которые объект проходит от корневого узла до листа. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "outlier_detector = OutlierForest(data_holder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### One-Class Support Vector Machines\n",
    "\n",
    "> Основная идея классического __метода опорных векторов (SVM)__ заключается в разделении объектов, относящихся к разным классам, гиперплоскостью так, чтобы максимизировать расстояние между ними. Алгоритм __OCSVM__, как следует из названия, обучается на данных, принадлежащих одному классу – классу нормальных объектов. Он определяет границы этих объектов и классифицирует все остальные точки, лежащие по другую сторону от разделяющей поверхности, как __аномальные__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "outlier_detector = OutlierOCSVM(data_holder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Local Outlier Factor\n",
    "\n",
    "> __Локальный уровень выброса (LOF)__ основывается на концепции локальной плотности объекта, где локальность задается его $k$ ближайшими соседями, расстояния до которых используются в качестве оценки плотности. Путем сравнения локальной плотности объекта с локальной плотностью его соседей, можно выделить области с аналогичной плотностью и точки, которые имеют существенно меньшую плотность, чем ее соседи. Эти точки считаются __выбросами__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "outlier_detector = OutlierLOF(data_holder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Cluster-Based Local Outlier Factor\n",
    "\n",
    "> В отличие от стандартного LOF, основанном на метрическом подходе к выявлению локальных выбросов, __CBLOF__ выявляет кластерную структуру данных, разделяет кластеры на \"большие\" и \"малые\" и затем определяет локальность малых кластеров по отношению к большим. Кластеры, чья локальность по отношению к другим мала, определяются как __выбросы__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "outlier_detector = OutlierCBLOF(data_holder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Помимо указанных 4 алгоритмов поиска аномалий, можно воспользоваться любым другим, который не встроен в библиотеку, но есть в pyod – например, __histogram-based outlier detection (HBOS)__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyod.models.hbos import HBOS\n",
    "\n",
    "hbos = HBOS(contamination=0.1)\n",
    "outlier_detector = OutlierCustom(data_holder, hbos, outlier_label=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "После выбора алгоритма, его следует применить с помощью метода __apply__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "outlier_detector.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты представляют собой список id аномалий (метод __get_outlier_ids__), таблицу с описательными статистиками по аномальным и нормальным объектам (метод __print_result__), а также графическую иллюстрацию важности использованных для поиска аномалий признаков (метод __show_permutation_importance__). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_detector.get_outlier_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_detector.print_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_detector.show_permutation_importance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `OutlierEnsemble`\n",
    "> `OutlierEnsemble` это композиция алгоритмов обнаружения аномалий, итоговой ответ которой представляет собой голосование (объект считается выбросом, если большинство алгоритмов определило его как выброс) следующих алгоритмов: [KNN](https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.knn), [ABOD](https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.abod), [HBOS](https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.hbos), [Isolation Forest](https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.iforest). В качестве алгоритмов можно выбрать любое подмножетво из {\"HBOS\", \"ABOD\", \"KNN\", \"IForest\"}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_detector = OutlierEnsemble(data_holder, [\"HBOS\", \"ABOD\", \"KNN\", \"IForest\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_detector.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_detector.print_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## IV. Факторный анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color='red'>В полной версии библиотеки</font>\n",
    "\n",
    "\n",
    "__Факторный анализ__ – это многомерный метод, применяемый для изучения взаимосвязей между значениями переменных. Предполагается, что известные переменные зависят от меньшего количества неизвестных переменных и случайной ошибки. С помощью факторного анализа возможно выявление скрытых переменных факторов, отвечающих за наличие линейных статистических корреляций между наблюдаемыми переменными.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Модуль автоматического построения моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color='red'>В полной версии библиотеки</font>\n",
    "\n",
    "\n",
    "Модуль автоматического построения моделей позволяет использовать методы машинного обучения для предсказания временных рядов и панельных данных. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Рекомендательная система"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color='red'>В полной версии библиотеки</font>\n",
    "\n",
    "\n",
    "Данный модуль представляет собой рекомендательную систему, ранжирующую этапы процесса в порядке их приоритетности для реинжениринга. Система показывает, на какие активности нужно обратить внимание в первую очередь при оптимизации процесса. Сначала выбирается лучшая модель, описывающую зависимость таргетной метрики (metric) каждой из Активностей от признаковых метрик (metric_f) всех остальных Активносетй. В качестве метрик могут выступать количество рециклов (количество появлений активности, __\"appearance\"__), время выполнения(__\"time\"__), количество повторений (__\"recycles\"__), кастомная метрика пользователя (\"__user_metric__\"). Далее на основании метрики строятся коэффициенты проблемности, в порядке убывания которых ранжируются Активности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VII. Анализ текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color='red'>В полной версии библиотеки</font>\n",
    "\n",
    "\n",
    "Данный модуль служит для кластеризации текстов. \n",
    "Для каждого кластера алгоритм выдает __номер кластера__ (название кластера или самое близкое сообщение к центроиду кластера), и 10 самых распространенных слов в кластере."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIII. Сентиментный анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color='red'>В полной версии библиотеки</font>\n",
    "\n",
    "\n",
    "Данный модуль представляет собой систему для анализа тональности словесных комментариев в текстовом поле. Модуль анализа тональности имеет два режима: «базовый» и «продвинутый». В «базовом» режиме тональность текста определяется как «positive» или «negative», численное значение тональности определяется в пределах от -1 до 1 (от негатива к позитиву)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IX. Поиск счастливого пути\n",
    "\n",
    "##### <font color='red'>В полной версии библиотеки</font>\n",
    "\n",
    "\n",
    "Задачу поиска счастливого пути можно решить с помощью обучения с подкреплением (RL), которое по своей сути адаптировано к поиску оптимальных действий. RL работает с двумя объектами: агентом и средой. Во время обучения агент взаимодействует с окружающей средой, совершает действия и получает обратную связь, которая называется вознаграждением. Задача формулируется в рамках марковского процесса принятия решений, который основан на:\n",
    "* множестве состояний в мире \n",
    "* множестве действий \n",
    "* вероятностном распределении следующего состояния при условии текущего состояния и завершенного действия \n",
    "* награды при переходе между состояниями при выполнении действий. \n",
    "\n",
    "Выполнение марковского свойства состоит в том, что следующее состояние условно не зависит от прошлых состояний и действий, учитывая текущее состояние и действие. Граф процесса рассматривается как среда, состояния — узлы графа (активности), действия — ребра (выбор следующей активности для перехода), награда — среднее отрицательное время перехода между прошлым и настоящим состояниями. При наличии ключевых состояний за переход в них также начисляется награда. Цель состоит в том, чтобы выбрать оптимальную политику — отображение из пространства состояний в пространство действий или, другими словами, руководство к действию в каждом состоянии — которое максимизирует ожидаемую дисконтированную сумму вознаграждений, проходящих через граф процесса.\n",
    "Оптимальная политика и, как следствие, путь находятся при помощи AutoRL с использованием лучшего по дисконтированной сумме наград  метода из:  value iteration,  Q-learning, cross entropy, genetic algorithm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X. Предсказание структуры графа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color='red'>В полной версии библиотеки</font>\n",
    "\n",
    "\n",
    "Модуль __GSPredictor__ (graph structure predictor) содержит алгоритм предсказания структуры графа, а именно, предсказываются две величины: вероятности и средние времена выполнения нод и рёбер графа. Эти величины представляются как временные ряды, получаемые из имеющихся данных, далее используются ml- и специализированные для работы с временными рядами алгоритмы для предсказания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## XI. Имитационное моделирование и what-if анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sberpm import DataHolder\n",
    "from sberpm.visual import GraphvizPainter\n",
    "from sberpm.miners import SimpleMiner, CausalMiner\n",
    "from sberpm.metrics import ActivityMetric, TransitionMetric\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_excel('example.xlsx')\n",
    "data.head()\n",
    "\n",
    "dh = DataHolder(\n",
    "    data=data,\n",
    "    id_column='id',\n",
    "    activity_column='stages',\n",
    "    start_timestamp_column='dt'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Имитационное моделирование и what-if анализ\n",
    "\n",
    "Модуль имитационного моделирования __`sberpm.imitation`__ позволяет симулировать процесс в as-is форме, вносить изменения в процесс и проводить what-if моделирование, а также оценивать схожесть симуляции по сравнению с исходным лог-файлом с помощью классов `Simulation` и `SimilarityMetric` соответственно. \n",
    "\n",
    "Класс Simulation содержит алгоритм симуляции идентичного лога процесса, а так же инструменты позволяющие изменять структуру графа процесса. \n",
    "\n",
    "Шаги алгоритма:\n",
    "\n",
    "I. __Подготовка данных__\n",
    "\n",
    "1. Генерация cross table с вероятностями переходов в ячейках таблицы\n",
    "    - В данные добавляются 'start' и 'end' события, они не отображаются в логах, но помогают при изменении структуры графа процесса (например если требуется добавить альтернативный вход в процесс, то используется следующая функция : __add_edge__('start', 'node_name', prob=float)) \n",
    "    - Создается матрица смежности (с количеством переходов в ячейках), после значения приводятся к вероятностям\n",
    "    \n",
    "2. Экстрагирование временных данных из оригинального лога, для сохранения картины распределения времени активностей.\n",
    "    - Из переданного data_holder сохраняются значения duration по активностям (далее они будут использованы при генерации новых этапов с идентичным распределением duration)\n",
    "\n",
    "II. __Генерация__\n",
    "\n",
    "0. Данные таблицы преобразовываются в словарь __{'action' : np.array({'action' : 'prob'})}__, считается интервал между временными точками входа в процесс (нужен чтобы получить start_timestamp для каждой итерации)\n",
    "1. В цикле генерируются логи процесса\n",
    "    - На каждой итерации рекурсивно строится цепочка активностей\n",
    "    - В лог записываются активности, время начала процесса и id процесса  \n",
    "    \n",
    "2. Генерация времени (длительности этапов): \n",
    "    - Если активность есть в оригинальном data_holder, то эти данные сжимаются\\растягиваются до количества этого этапа в сгенерированном логе\n",
    "    - Если активность отсутствует и при создании установлен like_node, то время генерируется с распределением, как у указанной активности (время будет масштабировано в зависимости от указанного mean_time)\n",
    "    - Если активность отсутствует и при создании не указан like_node, то берется значение среднего времени (или значение среднего по всем средним времени процесса, если при добавлении активности не было указано) и строится нормальное распределение.\n",
    "\n",
    "III. __Изменение структуры графа__\n",
    "\n",
    "Ниже указанны основные функции для работы со структурой графа.\n",
    "\n",
    "1. Удаление вершин и активностей\n",
    "    - __delete_node__(node, save_con=True) - удаляет активность по имени, флаг save_con означает будут ли сохранены соединения. \n",
    "        Пример: \n",
    "            A -> B -> C \n",
    "            delete_node('B', save_con=True) \n",
    "            A -> C\n",
    "    - __delete_edge__(node, node, side='right') - удаляет ребра (переходы) между переданными активностями, т.к связь может быть в обе стороны, применяется флаг side означающий будет ли связь слева направо, справа налево или в обе стороны.\n",
    "        Пример:\n",
    "            A <-> B\n",
    "            delete_edge('A', 'B', side='right')\n",
    "            A <- B\n",
    "\n",
    "2. Добавление ребер и активностей\n",
    "    - __add_node__(new_node, nodes=list, probabilities=list, mean_time=float, time_like='node', side='both') - добавление и связывание новой активности с переданным списком активностей, probabilities - вероятности перехода, mean_time - среднее время выполнения активности, side - в какую сторону будет связь, time_like - копирует распределение уже существующей активности (будет масштабировано в зависимости от mean_time)\n",
    "    - __add_edge__(node, node, prob, side) - добавление связи между активностями, prob - вероятности перехода, side - в какую сторону будет связь\n",
    "    - __swap_nodes__(node, node, save_probabilities=True) - меняет местами активности (вместе с распределением времени), save_probabilities - флаг указывающий на то, будут ли тянуться вероятности предшествующих нод при свапе активностей (если False, то производится перестановка и пересчет вероятностей)\n",
    "    \n",
    "    \n",
    "3. Изменение длительности и вероятностей\n",
    "    - __change_edge_prob__(node, node, prob=float) - изменяет вероятность перехода между активностями ( prob = 0, аналогичен удалению перехода)\n",
    "    - __scale_time_node__(node, scale=1) - изменяет время процесса (распределение останется прежним - как в оригинальном датасете), scale - это коэффициент уменьшения (если < 1) или увеличения (если > 1) продолжительности выполнения активности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sberpm.imitation import Simulation, SimilarityMetric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры `Simulation`\n",
    "- data_holder : DataHolder\n",
    "\n",
    "Методы класса `Simulation`:\n",
    "- __generate__ – запуск симуляции iterations (количество) цепочек активностей (id)\n",
    "- ___mean_duration__ – средняя длительность выполнения активностей или переходов в процессе\n",
    "- __scale_time_node__ – изменение времени выполнения активности\n",
    "- __change_edge_probability__ - изменяет вероятность перехода (ребра) в процессе\n",
    "- __delete_node__, __delete_edge__, __delete_loop__, __delete_all_loops__ – удаление ноды и ребра из процесса (delete_loop - удаляет ребро \"в себя\")\n",
    "- __add_edge__, __add_node__, __add_loop__ - добавление ноды и ребра в процесс (loop - добавляет ребро \"в себя\")\n",
    "- __swap_nodes__ – меняет местами ноды (с сохранением или с пересчетом вероятностей)\n",
    "- __get_result__ – возвращает результаты генерации \n",
    "- __compute_metric__ - считает различные метрики\n",
    "- __get_probabilities_tab__ - возвращает матрицу смежности, позволяет увидеть вероятности переходов\n",
    "\n",
    "На вход класс принимает объект типа DataHolder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация\n",
    "sim = Simulation(dh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As-is моделирование\n",
    "\n",
    "Метод __generate__ запускает симуляцию процесса. Он имеет параметры __iterations__ – число цепочек событий для симуляции. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.generate(1000)\n",
    "sim_data = sim.get_result()\n",
    "sim_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_dh = DataHolder(\n",
    "    data=sim_data,\n",
    "    id_column='id',\n",
    "    activity_column='stages',\n",
    "    start_timestamp_column='dt',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученный лог можно отрисовать с помощью майнера и встроенного инструмента для визуализации графов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_miner = SimpleMiner(generated_dh)\n",
    "simple_miner.apply()\n",
    "graph = simple_miner.graph\n",
    "\n",
    "painter = GraphvizPainter()\n",
    "painter.apply(graph)\n",
    "painter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What-if анализ\n",
    "\n",
    "Методы __delete_node__, __delete_edge__, __add_node__, __add_edge__, __add_loop__, __delete_loop__ и __swap_nodes__ позволяют изменять граф процесс. После запуска симуляции процесс будет реализовываться по альтернативным путям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаление нод\n",
    "sim.delete_node(\"Stage_5\")\n",
    "# удаление ребер (side=True - только в одну сторону)\n",
    "sim.delete_edge('Stage_7', 'Stage_5', side='right')\n",
    "# добавление ноды (action), nodes - лист связанных вершин с новой вершиной, probabilities - вероятности перехода в связанные вершины\n",
    "sim.add_node('Stages_10', \n",
    "             nodes=['Stage_8', 'Stage_5', 'Stage_10'], \n",
    "             probabilities=[0.15, 0.35], mean_time=3333, side='both')\n",
    "# добавление вершины, prob - вероятность перехода в нее\n",
    "sim.add_edge('Stage_7', 'Stage_7', prob=0.15, side='right')\n",
    "\n",
    "# работа с петлями (можно писать и sim.add_edge('node1', 'node1', prob=0.5))\n",
    "sim.delete_loop('Stage_10')\n",
    "\n",
    "# меняет местами ноды и их среднее время (вероятности не меняет)\n",
    "sim.swap_nodes('Stage_2', 'Stage_0', save_probabilities=False)\n",
    "\n",
    "sim.generate(5000)\n",
    "\n",
    "sim.get_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того чтобы контролировать то, как изменяются вероятности переходов между action в графе процесса, был добавлен метод __get_probabilities_tab__. Он возвращает таблицу переходов : столбец слева - это action \"откуда\", строка сверху - это \"куда\" делается переход, значения в ячейках это вероятности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.get_probabilities_tab()\n",
    "\n",
    "sim.change_edge_probability('Stage_10', 'Stage_10', 3)\n",
    "sim.change_edge_probability('Stage_9', 'end', 0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью метода __scale_time_node__ можно изменить время процесса (обратите внимание, распределение останется прежним - как в оригинальном датасете), scale - это коэффициент уменьшения (если < 1) или увеличения (если > 1) продолжительности выполнения активности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.scale_time_node('Stage_4', scale=1.5)\n",
    "sim.scale_time_node('Stage_3', scale=0.75)\n",
    "\n",
    "sim.generate(10000)\n",
    "sim_data = sim.get_result()\n",
    "sim_data.shape\n",
    "\n",
    "generated_dh = DataHolder(\n",
    "    data=sim.get_result(),\n",
    "    id_column='id',\n",
    "    activity_column='stages',\n",
    "    start_timestamp_column='dt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_miner = SimpleMiner(generated_dh)\n",
    "simple_miner.apply()\n",
    "graph = simple_miner.graph\n",
    "\n",
    "painter = GraphvizPainter()\n",
    "painter.apply(graph)\n",
    "painter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  XII. Decision Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модуль __`sberpm.decision_mining`__ предназначен для проведения __decision point analysis__, который заключается в определении причин, почему процесс идет по тому или иному пути. Класс `DecisionMining` выявляет, как те или иные свойства (атрибуты) процесса влияют на выбор конкретного пути. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sberpm.decision_mining import DecisionMining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На вход `DecisionMining` принимает объект типа DataHolder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация\n",
    "dm = DecisionMining(data_holder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DecisionMining` имеет следующие методы:\n",
    "- __print_decision_points__ – выводит decision points (активности, после которых идет выбор)\n",
    "- __apply__ – выполняет анализ decision points, строя дерево решений по указанным атрибутам\n",
    "- __get_clf_metrics__ – выводит метрики классификации\n",
    "- __plot_confusion_matrix__ – рисует матрицы ошибок\n",
    "- __plot_feature_importance__ – рисует важность признаков в дереве\n",
    "- __plot_feature_distribution__ – рисует распределение признаков по классам \n",
    "- __plot_decision_tree__ – рисует дерево решений\n",
    "- __print_decision_rule__ – выводит решающие правила"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision points – точки, где процесс имеет разветвление, можно посмотреть с помощью метода __print_decision_points__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.print_decision_points()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод __apply__ запускает алгоритм decision mining. Он имеет следующие параметры:\n",
    "- __categorical_attrs__ – названия категориальных признаков\n",
    "- __noncategorical_attrs__ – названия некатегориальных признаков\n",
    "- __decision_points__ – точки, по которым необходимо построить деревья решений, по умолчанию рассматриваются все\n",
    "- __sampling__ – нужен ли sampling (over- или under-), следует использовать в случае несбалансированных классов\n",
    "- __tree_params__ – параметры дерева решений\n",
    "- __grid_search__ – нужен ли подбор оптимальных гиперпараметров дерева решений\n",
    "- __param_grid__ – сетка параметров, используется только при grid_search=True\n",
    "- __random_state__ – используется в дереве решений и sampling\n",
    "- __n_jobs__ – используется в sampling и grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.apply(categorical_attrs=[data_holder.user_column],\n",
    "         noncategorical_attrs=[data_holder.duration_column],\n",
    "         decision_points='all', \n",
    "         sampling='RandomOverSampler',\n",
    "         tree_params='default',\n",
    "         grid_search=False, \n",
    "         param_grid='default',\n",
    "         random_state=42,\n",
    "         n_jobs=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты классификации можно посмотреть с помощью методов __get_clf_metrics__, __plot_confusion_matrix__ и __plot_feature_importance__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.get_clf_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество невысокое из-за особенностей синтетического датасета."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все plot методы имеют параметры:\n",
    "- __decision_points__ – точки, для которых необходимо изобразить харатеристики\n",
    "- __savefig__ – нужно ли сохранить изображение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.plot_confusion_matrix(decision_points=['Stage_0'], savefig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.plot_feature_importance(decision_points=['Stage_0'], savefig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод __plot_feature_importance__ дополнительно имеет еще два параметра:\n",
    "- __drop_outliers__ – нужно ли удалить выбросы для количественных признаков\n",
    "- __clf_results__ – нарисовать распределение признаков по результатам классификации (True) или по исходному логу (False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.plot_feature_distribution(decision_points=['Stage_0'], drop_outliers=True, clf_results=True, savefig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Методы __plot_decision_tree__ и __print_decision_rule__ выводят результаты работы decision mining алгоритма в виде дерева и правил соответственно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры __plot_decision_tree__:\n",
    "- __decision_points__ – точки, для которых необходимо нарисовать дерево решений\n",
    "- __max_depth__ – максимальная глубина дерева\n",
    "- __scale__ – масштаб графика\n",
    "- __savefig__ – нужно ли сохранить изображение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.plot_decision_tree(decision_points=['Stage_0'], max_depth=None, scale=1, savefig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры __print_decision_rule__:\n",
    "- __decision_points__ – точки, для которых необходимо вывести решающие правила\n",
    "- __paths__ – пути, по которым необходимо вывести решающие правила"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.print_decision_rule(decision_points=['Stage_0'], paths=['Stage_1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XIII. Хронометраж"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расчёт длительности процесса с предварительной очисткой выбросов при помощи алгоритмов машинного обучения.\n",
    "\n",
    "- __data_holder (SberPM DataHolder)__ - класс с хранящимися данными \n",
    "- __start_query__ (str) - запрос указывающий на начало нового процесса\n",
    "- __end_query__ (str) - запрос указывающий на окончание процесса\n",
    "- __query__ (str) - запрос указывающий на начало нового процесса или на завершение процесса в данной строке\n",
    "- __change_columns__ (List[str]) - список с названиями колонок по которым можно определить что начался новый процесс при изменении значения в колонке (например изменения идентификатора процесса или пользователя) \n",
    "- __sort_params__ (List[str]) - список названий колонок по которым будет производиться предварительная сортировка данных\n",
    "\n",
    "Параметры __query__, __start_query__, __end_query__ могут быть типа __\"sql\"__ или __\"pandas\"__, они оба должны ссылаться на фрейм данных как __\"df\"__, они должны возвращать один столбец: булевую маску или столбец из 0 и 1.\n",
    "\n",
    "В случае, если задаётся __\"sql\"__ запрос, то он должен выглядеть как __\"SELECT ... from df\"__.\n",
    "\n",
    "Метод __get_chrono()__ начнёт процесс расчёта длительности процесса и в результате выведет словарь(dict) с элементами:\n",
    "- среднее временя процесса в секундах\n",
    "- количество отобранных элементов\n",
    "- количество уникальных процессов\n",
    "- максимальное количество уникальных идентификаторов рассчитанных в хронометраже \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sberpm.ml.chronometrage import Chronometrage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('chrono_data.xlsx', engine='openpyxl')\n",
    "dh = DataHolder(df, 'process_id', 'event_type', 'data_timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_start_query = \"\"\"(df['event_type'] == 'Процесс_16961') & (df['event_action'].isin(['Начало']))\"\"\"\n",
    "example_end_query = \"\"\"(df['event_type'] == 'Процесс_16961') & (df['event_action'].isin(['Конец']))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = Chronometrage(dh, \n",
    "                   sort_params=['process_id', 'user_id', 'data_timestamp'], \n",
    "                   start_query=example_start_query,\n",
    "                   end_query=example_end_query,\n",
    "                   change_columns=['process_id', 'user_id'])\n",
    "res = cr.get_chrono()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "e4cce46d6be9934fbd27f9ca0432556941ea5bdf741d4f4d64c6cd7f8dfa8fba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
